{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping 2018 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as snsplt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import os\n",
    "\n",
    "import matplotlib.cm\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.colors import Normalize\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"https://raw.githubusercontent.com/cdriscoll92/CS-109A-Final-Project/master/data/\"\n",
    "local_data_folder = \"/Users/colleendriscoll/Dropbox/Classes/CS 109A/CS 109A Final project/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politico_url_front = \"https://www.politico.com/election-results/2018/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading in state abbreviations file to get the correct district ID columns\n",
    "state_abbs = pd.read_csv(data_folder + \"state_abbreviations_correspondence_table.csv\")\n",
    "\n",
    "## Politico site formatting for names\n",
    "states = list(state_abbs.state_name.str.lower().values)\n",
    "states_lower = [x.replace(\" \", \"-\") for x in states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BS_html_parsed_from_html(URL):\n",
    "    ## requires BeautifulSoup, time, requests\n",
    "    time.sleep(2)\n",
    "    bs_out = BeautifulSoup(requests.get(URL).text, \"html.parser\")\n",
    "    return(bs_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2018 = {'district': [],\n",
    "               'party': [],\n",
    "               'votes': []}\n",
    "for i, abb in enumerate(state_abbs.state_abb):\n",
    "    state_url = politico_url_front + states_lower[i]\n",
    "    ## Get state page\n",
    "    BS_page_state_i = BS_html_parsed_from_html(state_url)\n",
    "\n",
    "    ## Figure out how many districts there are in the state\n",
    "    district_links = BS_page_state_i.findAll(\"div\",\\\n",
    "                            {\"class\":\"district-links\"})\n",
    "\n",
    "    ## At-large districts don't have links and are referenced\n",
    "    ## differently from multi-district states    \n",
    "    if len(district_links) >0:\n",
    "        district_n = len(district_links[0].findAll(\"a\"))\n",
    "        districts_formatted = ['{num:02d}'.format(num=k) for k \\\n",
    "                            in range(1, district_n+1)]\n",
    "    else:\n",
    "        districts_formatted = ['00']\n",
    "\n",
    "    ## Get district tables\n",
    "    dist_ids = [abb+\"-\"+dist_i for dist_i in districts_formatted]\n",
    "    for district in dist_ids:\n",
    "        ## Get the section on the page for this district\n",
    "        district_html = BS_page_state_i.findAll(\"section\",\n",
    "                                                {\"id\": district})\n",
    "        ## Get the table where the results are\n",
    "        results_table = district_html[0].findAll(\"tr\")\n",
    "        \n",
    "        ## Table composed of headers and footers; only\n",
    "        ## grab candidate/vote information\n",
    "        last_candidate_index = len(results_table)-2\n",
    "        for j in range(1, last_candidate_index):\n",
    "            ## Get party and number of votes for each cand.\n",
    "            party = results_table[j].find(\"td\",\n",
    "                                          {\"class\":\"party\"})\n",
    "            votes = results_table[j].find(\"td\",\n",
    "                                          {\"class\":\"vote-count\"})\n",
    "\n",
    "            ## Add these results to the results dictionary\n",
    "            results_2018['district'].append(district)\n",
    "            results_2018['party'].append(party.text)\n",
    "            results_2018['votes'].append(votes.text)\n",
    "\n",
    "results_2018_df = pd.DataFrame(results_2018)\n",
    "results_2018_df.to_csv(local_data_folder + \"election_results/2018_scraped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Redistricting variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redist_data_path = \"/Users/colleendriscoll/Dropbox/Classes/CS 109A/CS 109A Final project/redistricting/\"\n",
    "\n",
    "states_df = pd.read_csv(redist_data_apath + \"FIPS.csv\")\n",
    "states_df.head()\n",
    "state_names = list(map(lambda x : str.lower(x) , states_df.name.values))\n",
    "state_abbrs = list(states_df.abbr.values)\n",
    "state_fips = list(states_df.fips_code.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abbr_for_state(state_name, state_names, state_abbrs):\n",
    "    try:\n",
    "        i = state_names.index(state_name.lower())\n",
    "    except ValueError:\n",
    "        return None\n",
    "    return state_abbrs[i]\n",
    "\n",
    "def dist_id_from_lewis(state_name, lewis_no, at_large=\"1\"):\n",
    "    result_state = abbr_for_state(state_name, state_names, state_abbrs)\n",
    "    if lewis_no == 0:\n",
    "        result_num = at_large\n",
    "    else:\n",
    "        result_num = \"{:d}\".format(int(lewis_no))\n",
    "    return \"{}_{}\".format(result_state, result_num)\n",
    "\n",
    "def map_id_from_lewis(state_names, lewis_nos, at_large=\"1\"):\n",
    "    return np.array(list(map(lambda s, n : dist_id_from_lewis(s, n, \"1\"),\n",
    "                             state_names, lewis_nos)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No states have been redistricted to a single at large district since the 2000 census. So we will ignore at-large districts in order to further minimize errors in producing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_hist_df = pd.read_csv(\n",
    "    redist_data_path +\n",
    "    \"e6311_post1948-shapeless.csv\"\n",
    ").sort_values(by=['congress', 'year', 'state_name', 'lewis_dist'])\n",
    "\n",
    "# filter for date range\n",
    "years_min = 2000\n",
    "years_max = 2017\n",
    "rows_in_years_range = (district_hist_df.year >= years_min) & (district_hist_df.year <= years_max)\n",
    "district_hist_df = district_hist_df[rows_in_years_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore at-large districts\n",
    "district_hist_df = district_hist_df[district_hist_df.lewis_dist != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEWIS_MOD = 1000\n",
    "FIPS_MOD = 1000000000 \n",
    "\n",
    "def abbr_from_fips(fips):\n",
    "    try:\n",
    "        i = state_fips.index(fips)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    return state_abbrs[i]\n",
    "\n",
    "def statename_from_fips(fips):\n",
    "    try:\n",
    "        i = state_fips.index(fips)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    return state_names[i]\n",
    "\n",
    "def dist_id_from_geomuid(geomuid, at_large=\"1\"):\n",
    "    lewis = geomuid % LEWIS_MOD\n",
    "    if lewis == 0 and at_large != \"0\":\n",
    "        lewis = at_large\n",
    "    fips_code = int(geomuid / FIPS_MOD)\n",
    "    return \"{}_{:d}\".format(abbr_from_fips(fips_code), int(lewis))\n",
    "\n",
    "def dists_from_geomuids(geomuids, at_large=\"1\"):\n",
    "    return np.array(list(map(lambda g : dist_id_from_geomuid(g, at_large), geomuids)))\n",
    "\n",
    "def get_all_year_dist(df):\n",
    "    # obtain a table of all congressional contests\n",
    "    years = df.year.values\n",
    "    dist_ids = dists_from_geomuids(df.geom_uid)\n",
    "    data = { 'year' : years, 'dist_id' : dist_ids }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "district_hist_df['dist_id'] = dists_from_geomuids(district_hist_df.geom_uid)\n",
    "all_possible = get_all_year_dist(district_hist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_info = pd.read_csv(\"congress_numbers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CON_START_MOD = 1000000\n",
    "CON_END_MOD = 1000\n",
    "\n",
    "def election_year(congress_no):\n",
    "    results = congress_info[congress_info.congress == congress_no].congressional_election.values\n",
    "    return results[0]\n",
    "\n",
    "def congress_no(year):\n",
    "    return congress_info[(congress_info.start <= year) & (congress_info.end > year)].congress.values[0]\n",
    "\n",
    "def start_congress(geomuid):\n",
    "    result = geomuid % FIPS_MOD\n",
    "    result -= (result % CON_START_MOD)\n",
    "    result /= CON_START_MOD\n",
    "    return result\n",
    "\n",
    "def end_congress(geomuid):\n",
    "    result = geomuid % CON_START_MOD\n",
    "    result -= (result % CON_END_MOD)\n",
    "    result /= CON_END_MOD\n",
    "    return result\n",
    "\n",
    "def year_from_geomuid(geomuid):\n",
    "    return election_year(start_congress(geomuid))\n",
    "\n",
    "texas_1_2004_ = 48109109001\n",
    "\n",
    "(\"congress {}: {}\".format(114, election_year(114)),\n",
    " \"{}: congress # {}\".format(2008, congress_no(2008)),\n",
    " \"{}: congress # {}\".format(2007, congress_no(2007)),\n",
    " \"{}[{:011d}]: {}-{} congress, election year {}\".format(\"Texas 1st District, 2004\",\n",
    "                                                        texas_1_2004_,\n",
    "                                                        start_congress(texas_1_2004_),\n",
    "                                                        end_congress(texas_1_2004_),\n",
    "                                                        year_from_geomuid(texas_1_2004_)\n",
    "                                                       )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redistricting(df, geom_uid_col, ignore_years=[]):  \n",
    "    unique_districts = df[geom_uid_col].drop_duplicates().sort_values().values\n",
    "    dist_id = dists_from_geomuids(unique_districts)\n",
    "    get_years = np.vectorize(year_from_geomuid)\n",
    "    years = get_years(unique_districts)\n",
    "    redistricted = np.full(dist_id.shape[0], True, dtype=bool)\n",
    "    data = {\n",
    "            'year' : years,\n",
    "            'dist_id' : dist_id,\n",
    "            'redistricted' : redistricted\n",
    "           }\n",
    "    redist_df = pd.DataFrame(data)\n",
    "    if len(ignore_years) > 0:\n",
    "        redist_df = redist_df.loc[~redist_df.year.isin(ignore_years)]\n",
    "    return redist_df\n",
    "\n",
    "redist_ = get_redistricting(district_hist_df, 'geom_uid', ignore_years=list(range(1990,1999,2)))\n",
    "print(redist_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate by getting redistricting counts by year\n",
    "def states_redistricting(df):\n",
    "    get_state = lambda dist : dist[0:2]\n",
    "    get_states_from_id = np.vectorize(get_state)\n",
    "    states = get_states_from_id(df.dist_id.values)\n",
    "    years = df.year.values\n",
    "    data = {'year' : years, 'state' : states}\n",
    "    return pd.DataFrame(data).drop_duplicates()\n",
    "\n",
    "df_states = states_redistricting(redist_)\n",
    "display(df_states.groupby(['year']).count())\n",
    "display(df_states.loc[df_states.year.isin([1998, 2000])].sort_values(['year', 'state']))\n",
    "\n",
    "display(redist_.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dists_for_state(state_abbr,dist_count):\n",
    "    return [\"{}_{}\".format(state_abbr, c) for c in range(1, dist_count + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest_district_count(df, state_abbr):\n",
    "    states = get_states_from_id(df.dist_id.values)\n",
    "    state_i = states == state_abbr\n",
    "    state_rows = df[state_i]\n",
    "    latest_year = state_rows[state_rows.year == np.max(state_rows.year.values)]\n",
    "    return latest_year.shape[0]\n",
    "\n",
    "def generate_redist_rows(state, year, dist_count, is_redist=True):\n",
    "    dists = []\n",
    "    for i in range(1, dist_count + 1):\n",
    "        dists.append(\"{}_{}\".format(state, i))\n",
    "    years = np.full(dist_count, year, dtype=int)\n",
    "    redist = np.full(dist_count, is_redist, dtype=bool)\n",
    "    data = { 'year' : years, 'dist_id' : dists, 'redistricted' : redist }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_redist_multi(state_tuples):\n",
    "    df = None\n",
    "    for st in state_tuples:\n",
    "        result = generate_redist_rows(st[0], st[1], st[2])\n",
    "        if df is None:\n",
    "            df = result\n",
    "        else:\n",
    "            df = df.append(result)\n",
    "    return df\n",
    "\n",
    "additional_redistricting = [(\"NC\", 2016, 13),\n",
    "                            (\"PA\", 2018, 18),\n",
    "                            (\"VA\", 2016, 11)]\n",
    "redist_df = redist_.append(generate_redist_multi(additional_redistricting), sort=False)\n",
    "redist_df.sort_values(['year', 'dist_id']).to_csv(redist_data_path + \"redist_2000-2018.csv\",\n",
    "                                                  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading in state abbreviations file to get the correct district ID columns\n",
    "state_abbs = pd.read_csv(data_folder + \"state_abbreviations_correspondence_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grouping CLEA by district-year to get the \n",
    "## democratic share of the two-party vote\n",
    "def group_to_D_vote(groupby_obj, democrat_code):\n",
    "    ## Groupby object with \"yr\", \"dist_id\", \"pty\", \"\"\n",
    "    years = []\n",
    "    dist_ids = []\n",
    "    dem_shares = []\n",
    "    \n",
    "    for name, group in groupby_obj:\n",
    "        dem_share = 0\n",
    "        years.append(group.yr.values[0])\n",
    "        dist_ids.append(group.dist_id.values[0])\n",
    "\n",
    "        if democrat_code in group.pty.values: ## If a Democrat ran\n",
    "            total_votes = np.sum(group.cv1.values)\n",
    "            dem_votes = np.sum(group.cv1[group.pty == democrat_code].values)\n",
    "            dem_share = dem_votes/total_votes\n",
    "        dem_shares.append(dem_share)\n",
    "    \n",
    "    dem_vote_share_dict = {'year': years,\n",
    "                           'dist_id': dist_ids,\n",
    "                           'dem_vote_share': dem_shares\n",
    "                          }\n",
    "    return(dem_vote_share_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clea_clean(clea_file_name, state_abb_df):\n",
    "    ## Read in data\n",
    "    clea_results = pd.read_csv(clea_file_name)\n",
    "    democrat_code = 180\n",
    "    republican_code = 583\n",
    "    election_month_int = 11\n",
    "    \n",
    "    ## Subsetting to only Democrats and Republicans\n",
    "    clea_results = clea_results[(clea_results.pty == democrat_code) | \n",
    "                                (clea_results.pty == republican_code)]\n",
    "    ## Only general elections (November)\n",
    "    clea_results = clea_results[clea_results.mn == election_month_int]\n",
    "\n",
    "    ## Extracting district number from constituency name\n",
    "    ## There are some states with only one district that then don't \n",
    "    ## have a district number listed -- therefore filling those NAs with 1s\n",
    "    clea_results['dist_num'] = clea_results.cst_n.str.findall('[0-9]+').\\\n",
    "    str[0].fillna(1)\n",
    "    \n",
    "    ## Lowercase state name to match CLEA listing\n",
    "    state_abb_df['state_name_lower'] = state_abb_df.state_name.str.lower()\n",
    "\n",
    "    ## Merging CLEA with state abbrevation correspondence table\n",
    "    clea_merged = pd.merge(clea_results, state_abb_df,\n",
    "                              how = 'right',\n",
    "                              left_on = 'sub',\n",
    "                              right_on = 'state_name_lower')\n",
    "    \n",
    "    ## Creating distict ID variable to merge on later\n",
    "    clea_merged['dist_id'] = clea_merged['state_abb']+ \"_\" + \\\n",
    "    clea_merged['dist_num'].astype(str)\n",
    "\n",
    "    ## Grouping CLEA by district-year to get the democratic share of the \n",
    "    ## two-party vote\n",
    "    grouped = clea_merged.groupby(['dist_id', 'yr'])\n",
    "    \n",
    "    dem_vote_share = pd.DataFrame(group_to_D_vote(grouped, \n",
    "                                                 democrat_code))\n",
    "    \n",
    "    return dem_vote_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clea_cleaned = clea_clean(data_folder + \"election_results/clea_20180507.csv\",\n",
    "                          state_abbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2018_df = pd.read_csv(local_data_folder + \n",
    "                           \"election_results/2018_scraped_cleaned.csv\")\n",
    "grouped_2018 = results_2018_df.groupby(['dist_id', 'yr'])\n",
    "results_2018 = pd.DataFrame(group_to_D_vote(grouped_2018, \"D\"))\n",
    "election_results = pd.concat([clea_cleaned, results_2018],\n",
    "                             ignore_index=True)\n",
    "\n",
    "## Make sure that no observations were lost/added in the concatenation\n",
    "assert (len(clea_cleaned)+ len(results_2018) ==\\\n",
    "        len(election_results)), \\\n",
    "\"Combined DataFrame not same length as two DFs combined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drop_secondary_members(nominate_df):\n",
    "    ## Support function for NOMINATE cleaning\n",
    "    ## Districts where there was more than one member of Congress serving, \n",
    "    ## assign the one who voted the most number of times to the district\n",
    "    multiple_member_districts = nominate_df.dist_id\\\n",
    "    [nominate_df.dist_id.duplicated()]\n",
    "    \n",
    "    nominate_df['main_member'] = 1\n",
    "    for district in multiple_member_districts:\n",
    "        member_votes = nominate_df.nominate_number_of_votes\\\n",
    "        [nominate_df.dist_id == district]\n",
    "\n",
    "        orders = np.argsort(member_votes)\n",
    "\n",
    "        lowest_score_index = nominate_df['main_member']\\\n",
    "        [nominate_df.dist_id == district][orders == 0].index\n",
    "\n",
    "        nominate_df.loc[lowest_score_index, 'main_member'] = 0\n",
    "\n",
    "    ## Only keeping the main member in each district\n",
    "    nominate_df = nominate_df[nominate_df.main_member == 1]\n",
    "    nominate_df = nominate_df.drop(columns = ['main_member'], axis = 1,\n",
    "                                   inplace = False)\n",
    "\n",
    "    return nominate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nominate_scores_clean(nom_file_name, cols_keep):\n",
    "    nominate_scores = pd.read_csv(nom_file_name)\n",
    "    nominate_scores = nominate_scores[cols_keep]\n",
    "    \n",
    "    ## Dropping president\n",
    "    nominate_scores = nominate_scores[nominate_scores['state_abbrev']\\\n",
    "                                      != \"USA\"]\n",
    "\n",
    "    ## Dropping members who didn't vote (they can't provide ideology measures then)\n",
    "    missing_vote_num_indices = nominate_scores.nominate_number_of_votes.isna()\\\n",
    "    == True\n",
    "    nominate_scores = nominate_scores[~missing_vote_num_indices]\n",
    "\n",
    "    ## District ID column\n",
    "    nominate_scores['dist_id'] = nominate_scores.state_abbrev + '_' + \\\n",
    "    nominate_scores.district_code.astype(str)\n",
    "\n",
    "    nominate_scores = drop_secondary_members(nominate_scores)\n",
    "\n",
    "    nominate_scores.drop('nominate_number_of_votes', axis = 1,\n",
    "                        inplace = True)\n",
    "\n",
    "    ## Election year during which this Congress was in session (not the one that\n",
    "    ## produced this Congress!)\n",
    "    session_length = 2\n",
    "    congress_start_year = 1788\n",
    "    nominate_scores['year'] = congress_start_year + session_length*\\\n",
    "    nominate_scores['congress']\n",
    "\n",
    "    return nominate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominate_csvs = os.listdir(local_data_folder + \"nominate_scores\")\n",
    "nominate_csvs_full = [local_data_folder + \"nominate_scores/\" + x \\\n",
    "                     for x in nominate_csvs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_cols_keep = ['congress', 'icpsr', 'district_code',\n",
    "                'state_abbrev', 'party_code', 'bioname', 'born',\n",
    "                'nominate_dim1', 'nominate_dim2','nominate_number_of_votes',\n",
    "                'nokken_poole_dim1', 'nokken_poole_dim2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_combined = nominate_scores_clean(nominate_csvs_full[0],\n",
    "                                nom_cols_keep)\n",
    "\n",
    "for file_path in nominate_csvs_full[1:]:\n",
    "    df = nominate_scores_clean(file_path, nom_cols_keep)\n",
    "    nom_combined = nom_combined.append(df, ignore_index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_elections_ideology = pd.merge(election_results, nom_combined, how = \"left\", \n",
    "                                     on = [\"year\", \"dist_id\"])\n",
    "merged_elections_ideology['age'] = merged_elections_ideology['year'] - \\\n",
    "merged_elections_ideology['born']\n",
    "\n",
    "merged_elections_ideology['dem_incumbent'] = 0\n",
    "merged_elections_ideology['dem_incumbent'][merged_elections_ideology.party_code == 100] = 1\n",
    "merged_elections_ideology = merged_elections_ideology.drop(\\\n",
    "    ['district_code','state_abbrev', 'bioname', 'born', 'party_code'],\n",
    "                                                           axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_columns(df, by_cols, lag_cols, n_lag_terms):\n",
    "    df.sort_values(by = by_cols,inplace=True)\n",
    "    # 1) Create new columns\n",
    "    new_col_names = [x+\"_lag\"+ str(i) for x in list(lag_cols) \\\n",
    "                     for i in range(1,n_lag_terms+1)]\n",
    "    for new_col_name in new_col_names:\n",
    "        df[new_col_name] = 'NaN'\n",
    "    new_columns_dict = {x: [] for x in new_col_names}\n",
    "    \n",
    "    # Unique district IDs, for example\n",
    "    groupby_values = df[by_cols[0]].unique()\n",
    "    for val in groupby_values: ## in each district\n",
    "        \n",
    "        for lag_term in range(1, n_lag_terms+1): ## For each year lagged\n",
    "            ## Get the right column name -- matches the one above\n",
    "            new_col_name = lag_cols[0] + \"_lag\"+str(lag_term)\n",
    "            ## Shift values using pd.DataFrame.shift()\n",
    "            lagged_vals = df[df[by_cols[0]] == val][lag_cols[0]].shift(lag_term).values\n",
    "            ## Insert lagged values back into the main data frame\n",
    "            ## This is where the problem is\n",
    "            new_columns_dict[new_col_name].extend(lagged_vals)\n",
    "    \n",
    "    for key in new_columns_dict:\n",
    "        df[key] = new_columns_dict[key]\n",
    "        \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lagged vote share\n",
    "merged_elections_ideology = lag_columns(merged_elections_ideology,\n",
    "                                        ['dist_id', 'year'],\n",
    "                                        ['dem_vote_share'], 1)\n",
    "merged_elections_ideology = merged_elections_ideology.rename(\n",
    "    columns={'dem_vote_share_lag1':'dem_prior_vote_share'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntl_df = pd.read_csv(local_data_folder + \"national_government_makeup.csv\")\n",
    "merged_elections_ideology = pd.merge(merged_elections_ideology, ntl_df,\n",
    "                                     how = \"left\", on = \"year\")\n",
    "\n",
    "## President = binary(0,1) = [Republican, Democrat]\n",
    "## House, Senate = float(0,1) = proportion seats held by Democrats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS_data = pd.read_csv(local_data_folder + \"ACS_2005_2017.csv\")\n",
    "\n",
    "## Scaling columns to be proportions, not absolute numbers\n",
    "columns_to_scale = ['bach_deg_num','black_pop','high_school_num','white_pop']\n",
    "new_column_names = ['bachelor_deg_perc', 'black_perc', 'HS_diploma_perc', 'white_perc']\n",
    "for i, colname in enumerate(columns_to_scale):\n",
    "    ACS_data[new_column_names[i]] = ACS_data[colname]/ACS_data['total_pop']\n",
    "\n",
    "ACS_data = ACS_data.drop(columns_to_scale, axis = 1, inplace = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS_data = pd.merge(ACS_data, state_abbs[['state_name', 'state_abb']],\n",
    "                   how = \"left\", on = \"state_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS_data['dist_id'] = ACS_data['state_abb'] + \"_\"+ \\\n",
    "ACS_data['district_num'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['district_num', 'state_name', 'state_abb', 'total_pop']\n",
    "ACS_data = ACS_data.drop(cols_to_drop, axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using earliest data (2017) to predict the 2018 election\n",
    "## So for the merge to work, we have to recode the year of \n",
    "## the 2017 data for 2018.\n",
    "\n",
    "ACS_data['year'][ACS_data.year == 2017] = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.merge(merged_elections_ideology, ACS_data,\n",
    "                        how = \"left\", on = ['dist_id', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping NAs\n",
    "combined_data = combined_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Redistricting variable\n",
    "def merge_redist(df, redist_df, year_col='year', dist_id_col='dist_id'):\n",
    "    merged_df = df.merge(redist_df, on=(year_col, dist_id_col), how='left')\n",
    "    merged_df.redistricted.fillna(0, inplace=True)\n",
    "    return merged_df\n",
    "\n",
    "redist_df = pd.read_csv(local_data_folder + \"redist_2000-2018.csv\")\n",
    "\n",
    "combined_data = merge_redist(combined_data, redist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.to_csv(local_data_folder + \"combined_data.csv\",\n",
    "                     index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv(local_data_folder + \"combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_plot_vars = ['median_HH_income', 'median_age','mortgage_cost',\n",
    "                    'unemp_rate', 'bachelor_deg_perc', 'black_perc',\n",
    "                    'HS_diploma_perc', 'white_perc']\n",
    "\n",
    "years = combined_data.year.unique()\n",
    "\n",
    "col_n, row_n = 2,4\n",
    "\n",
    "fig, ax  = plt.subplots(nrows=row_n, ncols=col_n, figsize=(5*col_n,5*row_n))\n",
    "fig.suptitle(\"Distribution of Predictor Variables Over Time, 2006 - 2018\",\n",
    "            y = 0.95, fontsize = \"xx-large\")\n",
    "fig.subplots_adjust(left=None, bottom=None, right=None,\n",
    "                    top=None, wspace=0.2, hspace=0.5)\n",
    "ax = ax.flatten()\n",
    "for i, var in enumerate(violin_plot_vars):\n",
    "    medians = []\n",
    "    medians_x = []\n",
    "    for j, y in enumerate(years):\n",
    "        violin_plot_data = combined_data[var][combined_data.year == y]\n",
    "        medians_x.append(j)\n",
    "        medians.append(np.median(violin_plot_data.values))\n",
    "        ax[i].violinplot(violin_plot_data.values,\n",
    "                         positions = [j])\n",
    "    ax[i].plot(medians_x, medians, \"o-\", label = \"Median\")\n",
    "    ax[i].set_xticks([0,1,2,3,4,5,6,7])\n",
    "    ax[i].set_xticklabels(years)\n",
    "    ax[i].set_title(var)\n",
    "    ax[i].set_xlabel(\"Year\")\n",
    "    min_val = np.min(combined_data[var])\n",
    "    max_val = np.max(combined_data[var])\n",
    "    min_max_range = max_val - min_val\n",
    "    ax[i].set_ylim(min_val - 0.05*min_max_range,\n",
    "                  max_val + 0.2*min_max_range)\n",
    "    ax[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_n, row_n = 3,3\n",
    "\n",
    "fig, ax  = plt.subplots(nrows=row_n, ncols=col_n, figsize=(5*col_n,5*row_n))\n",
    "fig.suptitle(\"Histogram of Election Winners by Margin of Victory, 2006 - 2018\",\n",
    "            y = 0.95, fontsize = \"xx-large\")\n",
    "fig.subplots_adjust(left=None, bottom=None, right=None,\n",
    "                    top=None, wspace=0.2, hspace=0.5)\n",
    "ax = ax.flatten()\n",
    "for i, year in enumerate(combined_data.year.unique()):\n",
    "    histogram_values = combined_data.dem_vote_share[\n",
    "        combined_data.year == year].values\n",
    "    republican_winners = [x for x in histogram_values if x < 0.5]\n",
    "    democrat_winners = [x for x in histogram_values if x >= 0.5]\n",
    "    ax[i].hist(republican_winners, color = \"red\",\n",
    "                           label = \"Rep. winner\")\n",
    "    ax[i].hist(democrat_winners, color = \"blue\",\n",
    "                           label = \"Dem. winner\")\n",
    "    ax[i].set_ylim(0, 65)\n",
    "    ax[i].set_title(year)\n",
    "    ax[i].set_xlabel(\"Margin of Victory\")\n",
    "    ax[i].set_ylabel(\"Count of Districts\")\n",
    "    ax[i].set_xticks([0, 0.25, 0.5, 0.75, 1])\n",
    "    ax[i].set_xticklabels([\"R+100\", \"R+50\", \"Tie\",\"D+50\",\"D+100\"])\n",
    "    ax[i].legend()\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression on training data \n",
    "\n",
    "## Extracting 2016 data to use as training outcome\n",
    "results_2016 = combined_data[combined_data.year == 2016]\\\n",
    "[['dist_id', 'year', 'dem_vote_share']]\n",
    "\n",
    "results_2016.columns = ['dist_id', 'year', 'dem_vote_share_2016']\n",
    "results_2016['dem_won_2016'] = np.round(results_2016.dem_vote_share_2016)\n",
    "results_2016 = results_2016.drop('dem_vote_share_2016', axis = 1,\n",
    "                                inplace = False)\n",
    "\n",
    "train_data = combined_data[combined_data.year <2018]\n",
    "\n",
    "train_data = pd.merge(train_data, results_2016[['dist_id', 'dem_won_2016']],\n",
    "                     how = \"left\", on = 'dist_id')\n",
    "\n",
    "results_2016 = train_data[train_data.year == 2016][['dist_id','dem_vote_share']]\n",
    "results_2016.columns = ['dist_id', 'dem_vote_share_2016']\n",
    "\n",
    "train_data = pd.merge(train_data, results_2016,\n",
    "                     how = \"left\", on = \"dist_id\")\n",
    "\n",
    "train_data = train_data.drop(\"dem_vote_share\", axis = 1,\n",
    "                            inplace = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(local_data_folder + 'train_data.csv',\n",
    "                 index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping unnecessary columns\n",
    "cols_to_drop_for_train = ['dist_id', 'congress', 'icpsr']\n",
    "\n",
    "# Fit logistic regression on training data \n",
    "data_to_fit_base = train_data.drop(cols_to_drop_for_train,\n",
    "                                      axis = 1,\n",
    "                                      inplace = False)\n",
    "data_to_fit_base = data_to_fit_base.dropna(inplace = False)\n",
    "data_to_fit_base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAINING SETS\n",
    "x_train = data_to_fit_base\n",
    "y_train = x_train.dem_won_2016.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_base = LogisticRegression(C=100000)\n",
    "logreg_base.fit(x_train.dem_prior_vote_share.values.reshape(-1, 1),\n",
    "            y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction and check the accuracy\n",
    "y_train_probs=(logreg_base.predict_proba(x_train.dem_prior_vote_share\\\n",
    "                                     .values.reshape(-1, 1)))\n",
    "\n",
    "train_accuracy = logreg_base.score(x_train.dem_prior_vote_share\\\n",
    "                               .values.reshape(-1, 1),\n",
    "                            y_train)*100\n",
    "\n",
    "print('Accuracy of baseline logistic regression classifier on train set: ',\n",
    "      np.round(train_accuracy, 2), \"%\", sep = \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test results\n",
    "y_test_continuous = combined_data[combined_data.year == 2018]['dem_vote_share']\n",
    "y_test = np.round(y_test_continuous, 0)\n",
    "x_test = combined_data[combined_data.year == 2018]['dem_prior_vote_share']\n",
    "\n",
    "test_accuracy = logreg_base.score(x_test.values.reshape(-1, 1),\n",
    "                                  y_test)*100\n",
    "\n",
    "print('Accuracy of baseline logistic regression classifier on test set: ',\n",
    "      np.round(test_accuracy, 2), \"%\", sep = \"\")\n",
    "\n",
    "y_test_predict_probs=(logreg_base.predict_proba(x_test.values.reshape(-1, 1)))\n",
    "y_test_predict_bool = (logreg_base.predict(x_test.values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## True outcomes:\n",
    "\n",
    "x_train_true = x_train['dem_prior_vote_share'].values\n",
    "y_train_true = x_train['dem_vote_share_2016'].values\n",
    "\n",
    "print(len(x_train_true) == len(y_train_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot predicted probabilities\n",
    "accurate = np.where(y_test_predict_bool == y_test.values)\n",
    "inaccurate = np.where(y_test_predict_bool != y_test.values)\n",
    "## Data\n",
    "plt.plot(x_test.values[accurate],\n",
    "         y_test_continuous.values[accurate], \"o\",\n",
    "        label = \"Accurate\")\n",
    "plt.plot(x_test.values[inaccurate],\n",
    "         y_test_continuous.values[inaccurate], \"o\",\n",
    "        label = \"Inaccurate\")\n",
    "plt.plot(x_test.values[np.argsort(y_test_predict_probs[:,1])],\n",
    "         y_test_predict_probs[:,1][np.argsort(y_test_predict_probs[:,1])],\n",
    "         '-',linewidth = 3, color = \"k\",\n",
    "         label='Predicted probabilities')\n",
    "## 50% lines\n",
    "plt.axhline(0.5, linestyle = \"--\", color = \"black\")\n",
    "plt.axvline(0.5, linestyle = \"--\", color = \"black\")\n",
    "plt.xlabel('2016 Election Results')\n",
    "plt.ylabel('2018 Election Result\\n(Actual and Predicted)')\n",
    "plt.title('Baseline Model:\\nPredicted Probabilities of Democrat Winning, 2018')\n",
    "plt.xticks([0, 0.25, 0.5, 0.75, 1],\n",
    "          [\"R+100\", \"R+50\", \"Tie\",\"D+50\",\"D+100\"])\n",
    "plt.yticks([0, 0.25, 0.5, 0.75, 1],\n",
    "          [\"R+100\", \"R+50\", \"Tie\",\"D+50\",\"D+100\"])\n",
    "plt.xlim(-0.03, 1.03)\n",
    "plt.ylim(-0.03, 1.03)\n",
    "plt.legend(bbox_to_anchor=(1, 0.66))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lowest former vote share that predicts Democrat wins\n",
    "left_bound = 255\n",
    "right_bound = left_bound + 1\n",
    "y_test_predict_probs[:,1][np.argsort(y_test_predict_probs[:,1])]\n",
    "print(x_test.values[np.argsort(y_test_predict_probs[:,1])][right_bound])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data = Data for year 2018\n",
    "testdata=comb_data[comb_data.year==2018]\n",
    "\n",
    "#Train Data = Data for years other than 2018\n",
    "traindata=comb_data[comb_data.year!=2018]\n",
    "\n",
    "testdata.shape, traindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of predictors we want to use\n",
    "predictors=['year','nokken_poole_dim1', 'nokken_poole_dim2', 'age',\n",
    "            'dem_incumbent', 'dem_prior_vote_share',\n",
    "            'president', 'house', 'senate', 'median_HH_income',\n",
    "            'median_age', 'mortgage_cost', 'unemp_rate',\n",
    "            'bachelor_deg_perc', 'black_perc',\n",
    "            'HS_diploma_perc', 'white_perc', 'redistricted']\n",
    "\n",
    "#Columns to drop in Xtest and Xtrain\n",
    "columns_to_drop=set(comb_data.columns) - set(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response Variable for test and train data sets = Democrat Vote Share\n",
    "ytest=testdata.dem_vote_share\n",
    "ytrain=traindata.dem_vote_share\n",
    "\n",
    "\n",
    "#Xdata for test and train data\n",
    "xtest=testdata.drop(columns_to_drop, axis=1, inplace = False)\n",
    "xtrain=traindata.drop(columns_to_drop, axis=1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_table_cols_to_drop = ['dist_id', 'congress', 'icpsr',\n",
    "                          'nominate_dim1', 'nominate_dim2']\n",
    "corr_table_data = comb_data.drop(corr_table_cols_to_drop,\n",
    "                                axis = 1, inplace = False)\n",
    "## Reordering columns\n",
    "corr_table_data = corr_table_data[['year', 'dem_vote_share',\n",
    "                                   'dem_prior_vote_share', \n",
    "                                   'dem_incumbent',\n",
    "                                   'redistricted',\n",
    "                                   'president', 'house',\n",
    "                                   'senate', 'nokken_poole_dim1',\n",
    "                                   'nokken_poole_dim2', 'age',\n",
    "                                   'white_perc', 'black_perc',\n",
    "                                   'HS_diploma_perc',\n",
    "                                   'bachelor_deg_perc',\n",
    "                                   'unemp_rate', 'mortgage_cost',\n",
    "                                   'median_HH_income', 'median_age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(corr_table_data.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(np.round(corr_table_data.corr(), 2),\n",
    "            mask=mask, cmap=cmap,\n",
    "            center=0,annot=True,\n",
    "            square=True,\n",
    "            linewidths=.5,\n",
    "            cbar_kws={\"shrink\": .5})\n",
    "ax.set_title('Correlation heatmap between predictors and \\\n",
    "continuous outcome (`dem_vote_share`)')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the dem_vote_share to binary output\n",
    "def get_binary(response):\n",
    "    binary=[]\n",
    "    for i in range(len(response)):\n",
    "        if response.iloc[i] <0.5:\n",
    "            out=0 \n",
    "        else:\n",
    "            out = 1 \n",
    "        binary.append(out)\n",
    "    binary=pd.DataFrame(binary)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary response data\n",
    "binarytest=get_binary(ytest)\n",
    "binarytrain=get_binary(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression on training data \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg1 = LogisticRegression( C=100000)\n",
    "logreg1.fit(xtrain, binarytrain)\n",
    "\n",
    "# Make Prediction and check the accuracy\n",
    "y_test_probs=(logreg1.predict_proba(xtest))\n",
    "y_train_probs=(logreg1.predict_proba(xtrain))\n",
    "\n",
    "logreg1_testscore=logreg1.score(xtest, binarytest)\n",
    "logreg1_trainscore=logreg1.score(xtrain, binarytrain)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on \\\n",
    "train set: {0:.2f}%'.format(logreg1_trainscore*100))\n",
    "print('Accuracy of logistic regression classifier on \\\n",
    "test set: {0:.2f}%'.format(logreg1_testscore*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoretrain=[]\n",
    "scoretest=[]\n",
    "for i in range(1,25,2):\n",
    "    RF1= RandomForestClassifier(max_depth=i, n_estimators=40)\n",
    "    RF1.fit(xtrain, binarytrain)\n",
    "    scoretrain.append(accuracy_score(binarytrain,  RF1.predict(xtrain)))\n",
    "    scoretest.append(accuracy_score(binarytest,  RF1.predict(xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,25,2), scoretrain,'o')\n",
    "plt.plot(range(1,25,2), scoretest,'o')\n",
    "plt.title(\"Test and Training accuracies as a function of tree depth\")\n",
    "plt.xlabel(\"Tree Depth\")\n",
    "plt.ylabel(\"Accuracy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best tree depth = 3\n",
    "RF2= RandomForestClassifier(max_depth=15, n_estimators=40)\n",
    "RF2.fit(xtrain, binarytrain)\n",
    "\n",
    "y_predRF_train = RF2.predict(xtrain)\n",
    "y_predRF_test = RF2.predict(xtest)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "trainRF_score = accuracy_score(binarytrain, y_predRF_train)\n",
    "testRF_score = accuracy_score(binarytest, y_predRF_test)\n",
    "\n",
    "print(\"Random Forest Accuracy, Training Set : {0:.2f}%\".format(trainRF_score*100))\n",
    "print(\"Random Forest Accuracy, Testing Set: {0:.2f}%\".format(testRF_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging Classifier\n",
    "bag1 = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
    "bag1.fit(xtrain, binarytrain)\n",
    "bag1_trainscore=bag1.score(xtrain,binarytrain)\n",
    "bag1_testscore=bag1.score(xtest,binarytest)\n",
    "print(\"Bagging Accuracy, Training Set : {0:.2f}%\"\\\n",
    "      .format(bag1_trainscore*100))\n",
    "print(\"Bagging Accuracy, Testing Set: {0:.2f}%\"\n",
    "      .format(bag1_testscore*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Data to have mean = 1 and std =1\n",
    "#Ridge regression on Scaled Data\n",
    "xtrain_scaled=pd.DataFrame(preprocessing.scale(xtrain))\n",
    "xtest_scaled=pd.DataFrame(preprocessing.scale(xtest))\n",
    "ridge1= linear_model.Ridge(alpha=0.5)\n",
    "ridge1.fit(xtrain,ytrain)\n",
    "\n",
    "ridge1_testpred=pd.Series(ridge1.predict(xtest))\n",
    "binarytest_ridgepred=get_binary(ridge1_testpred)\n",
    "\n",
    "ridge1_trainpred=pd.Series(ridge1.predict(xtrain))\n",
    "binarytrain_ridgepred=get_binary(ridge1_trainpred)\n",
    "\n",
    "\n",
    "ridge1_testscore=accuracy_score(binarytest_ridgepred,binarytest)\n",
    "ridge1_trainscore=accuracy_score(binarytrain_ridgepred,binarytrain)\n",
    "\n",
    "print(\"Ridge Accuracy, Training Set : {0:.2f}%\"\\\n",
    "      .format(ridge1_trainscore*100))\n",
    "print(\"Ridge Accuracy, Testing Set: {0:.2f}%\"\\\n",
    "      .format(ridge1_testscore*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression with cross-validation and L1 regularization (Lasso)\n",
    "\n",
    "logregcv1 = LogisticRegressionCV(cv=5, penalty='l1',\n",
    "                                 solver='liblinear').fit(xtrain, binarytrain)\n",
    "logregcvlasso_testscore= logregcv1.score(xtest, binarytest) \n",
    "logregcvlasso_trainscore= logregcv1.score(xtrain, binarytrain) \n",
    "\n",
    "print(\"Lasso with CV Accuracy, Training Set : {0:.2f}%\"\\\n",
    "      .format(logregcvlasso_trainscore*100))\n",
    "print(\"Lasso with CV Accuracy, Testing Set: {0:.2f}%\"\\\n",
    "      .format(logregcvlasso_testscore*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression with cross-validation and L2 regularization (Ridge)\n",
    "\n",
    "logregcv2 = LogisticRegressionCV(cv=5, penalty='l2').fit(\\\n",
    "    xtrain, binarytrain)\n",
    "\n",
    "logregcvridge_testscore= logregcv2.score(xtest, binarytest) \n",
    "logregcvridge_trainscore= logregcv2.score(xtrain, binarytrain) \n",
    "\n",
    "print(\"Ridge with CV Accuracy, Training Set : {0:.2f}%\"\\\n",
    "      .format(logregcvridge_trainscore*100))\n",
    "print(\"Ridge with CV Accuracy, Testing Set: {0:.2f}%\"\\\n",
    "      .format(logregcvridge_testscore*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_table = {'classifier':['Logistic Regression',\n",
    "                                  'Logistic Regression with CV (Lasso)',\n",
    "                                  'Logistic Regression with CV (Ridge)',\n",
    "                                  'Linear Regression (Ridge)','Bagging',\n",
    "                                  'Random Forest'],                    \n",
    "                    'training accuracy':[logreg1_trainscore,\n",
    "                                         logregcvlasso_testscore,\n",
    "                                         logregcvridge_trainscore,\n",
    "                                         ridge1_trainscore,                    \n",
    "                                         bag1_trainscore,\n",
    "                                         trainRF_score],\n",
    "                    'test accuracy':[logreg1_testscore,\n",
    "                                     logregcvlasso_testscore, \n",
    "                                     logregcvridge_testscore,\n",
    "                                     ridge1_testscore,\n",
    "                                     bag1_testscore,\n",
    "                                     testRF_score]}\n",
    "\n",
    "accuracies_table_df = pd.DataFrame(accuracies_table)\n",
    "\n",
    "print(\"Summary of Models used:\")\n",
    "accuracies_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Interaction Terms\n",
    "poly = PolynomialFeatures(degree=3, interaction_only=False)\n",
    "xtrain_interact=poly.fit_transform(xtrain)\n",
    "xtest_interact=poly.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Logistic regression with interaction terms\n",
    "logreg2 = LogisticRegression(C=1)\n",
    "logreg2.fit(xtrain_interact, binarytrain)\n",
    "\n",
    "# Make Prediction and check the accuracy\n",
    "y_test_probs2=(logreg2.predict_proba(xtest_interact))\n",
    "y_train_probs2=(logreg2.predict_proba(xtrain_interact))\n",
    "\n",
    "logreg2_testscore=logreg2.score(xtest_interact, binarytest)\n",
    "logreg2_trainscore=logreg2.score(xtrain_interact, binarytrain)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on train set: {0:.2f}%'\\\n",
    "      .format(logreg2_trainscore*100))\n",
    "print('Accuracy of logistic regression classifier on test set: {0:.2f}%'\\\n",
    "      .format(logreg2_testscore*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test results\n",
    "y_test_continuous = ytest\n",
    "y_test = binarytest[0].values\n",
    "\n",
    "y_test_predict_bool = (logreg2.predict(xtest_interact))\n",
    "y_test_predict_cont = (logreg2.predict_proba(xtest_interact))\n",
    "\n",
    "# Plot predicted probabilities\n",
    "accurate_indices = np.where(y_test_predict_bool == y_test)\n",
    "inaccurate_indices = np.where(y_test_predict_bool != y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cols = corr_table_data.columns.drop(['dem_vote_share', 'year',\n",
    "                                         'president', 'house', 'senate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_n, row_n = 3,5\n",
    "\n",
    "fig, ax  = plt.subplots(nrows=row_n, ncols=col_n, figsize=(5*col_n,5*row_n))\n",
    "fig.suptitle(\"2018 Predictions by Predictor Variable\",\n",
    "            y = 0.91, fontsize = \"xx-large\")\n",
    "fig.subplots_adjust(left=None, bottom=None, right=None,\n",
    "                    top=None, wspace=0.5, hspace=0.5)\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, col in enumerate(plot_cols):\n",
    "    x_values = xtest[col].values\n",
    "    ## Data\n",
    "    ax[i].plot(x_values[accurate],\n",
    "             ytest.values[accurate], \"o\",\n",
    "            label = \"Accurate\")\n",
    "    ax[i].plot(x_values[inaccurate],\n",
    "             ytest.values[inaccurate], \"+\",\n",
    "            label = \"Inaccurate\")\n",
    "    ax[i].set_title(col)\n",
    "    ax[i].set_xlabel('Data Values')\n",
    "    ax[i].set_ylabel('2018 Election Outcome (Observed)')\n",
    "    ax[i].set_yticks([0, 0.25, 0.5, 0.75, 1])\n",
    "    ax[i].set_yticklabels([\"R+100\", \"R+50\", \"Tie\",\"D+50\",\"D+100\"])\n",
    "    ax[i].legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
